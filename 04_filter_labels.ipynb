{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import utils\n",
    "\n",
    "data_path = Path.cwd() / \"data\"\n",
    "#data_path = Path.cwd() / \"data_tiny\"\n",
    "\n",
    "input_png_dir = data_path / \"collect_data\"\n",
    "\n",
    "input_dir = data_path / \"labeled_data\"\n",
    "output_dir = data_path / \"labeled_filtered_data\"\n",
    "positive_list_path = data_path / \"filtered_list.txt\"\n",
    "#input_dir = data_path / \"merged_data\"\n",
    "#output_dir = data_path / \"merged_filtered_data\"\n",
    "#positive_list_path = data_path / \"positive_list_merged.txt\"\n",
    "\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "scale_factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(positive_list_path, \"r\") as f:\n",
    "    target_list = f.readlines()\n",
    "target_list = [l.strip() for l in target_list]\n",
    "target_list = [l.split(\":\") for l in target_list]\n",
    "target_list = [(f, l.split(\",\")) for f, l in target_list]\n",
    "target_list = [(f, [e.split(\"_\") for e in l]) for f, l in target_list]\n",
    "for e in itertools.chain.from_iterable([[len(e) for e in l] for _, l in target_list]):\n",
    "    assert(e == 2)\n",
    "\n",
    "target_list = [(f.strip(), [(int(e[0].strip()), int(e[1].strip())) for e in l]) for f, l in target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [(f\"{s}.txt\", l) for s, l in target_list]\n",
    "\n",
    "print(f\"#filtered_annotations: {len(target_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(params):\n",
    "    txt_filename, annotations = params\n",
    "\n",
    "    input_txt_path = input_dir / txt_filename\n",
    "    output_txt_path = output_dir / txt_filename\n",
    "\n",
    "    if not input_txt_path.exists():\n",
    "        print(input_txt_path.name, \"does not exist, skipped.\")\n",
    "        return None\n",
    "\n",
    "    with open(input_txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    image_size, areas = utils.parse_annotation(lines)\n",
    "    image_w, image_h = image_size\n",
    "\n",
    "    if len(areas) <= 0:\n",
    "        return None\n",
    "    \n",
    "    if len(areas) <= max([i for i, _ in annotations]):\n",
    "        print(target_file.name, \" annotation is not valid, skipped.\")\n",
    "        return None\n",
    "    \n",
    "    areas = [(areas[i], s) for i, s in annotations]\n",
    "    areas_scaled = []\n",
    "\n",
    "    for (x0, y0, x1, y1), scale in areas:\n",
    "        #print(x0, y0, x1, y1)\n",
    "        orig_w, orig_h = (x1 - x0, y1 - y0)\n",
    "        assert(orig_h > 0 and orig_w > 0)\n",
    "\n",
    "        remove_ratio = 1.0 - (1.0 - scale_factor) ** scale\n",
    "        trim_w = math.ceil(orig_w * remove_ratio * 0.5)\n",
    "        trim_h = math.ceil(orig_h * remove_ratio * 0.5)\n",
    "        x0 = min(x0 + trim_w, image_w - 1)\n",
    "        y0 = min(y0 + trim_h, image_h - 1)\n",
    "        x1 = max(x1 - trim_w, 0)\n",
    "        y1 = max(y1 - trim_h, 0)\n",
    "        #print(x0, y0, x1, y1)\n",
    "        assert(x0 < x1 and y0 < y1)\n",
    "\n",
    "        areas_scaled.append((x0, y0, x1, y1))\n",
    "\n",
    "        #break\n",
    "    areas = [f\"{x0} {y0} {x1} {y1} 1\" for x0, y0, x1, y1 in areas_scaled]\n",
    "\n",
    "    annotations = \"\\n\".join(areas)\n",
    "    annotations = f\"{image_size[0]} {image_size[1]}\\n{len(areas)}\\n{annotations}\"\n",
    "\n",
    "    with open(output_txt_path, \"w\") as f:\n",
    "        f.write(annotations)\n",
    "\n",
    "[process(p) for p in tqdm(parameters)]\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
